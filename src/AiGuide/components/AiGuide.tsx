// src/components/AiGuide.tsx

import React, { useEffect, useState, useRef } from "react";
import { useNavigate } from "react-router-dom";
// import Header from "../components/Header";
import { getChatHistory, sendTextQuestion, sendAudio } from "../../utils/api";

import "../styles/AiGuide.css";
import AiGuideChat from "./AiGuideChat";
import arrowUp from '../../assets/images/arrow-up.png';
import keyboard from '../../assets/images/keyboard.png';
import microphone from '../../assets/images/microphone.png';

interface Message {
    id: number;
    type: "user" | "bot";
    text: string;
    isNew?: boolean; // ìƒˆë¡œìš´ ë©”ì‹œì§€ ì—¬ë¶€
}

interface AiGuideProps {
    defaultMessage: string;
}

const AiGuide: React.FC<AiGuideProps> = ({defaultMessage }) => {
    const [messages, setMessages] = useState<Message[]>([]);
    const [textQuestion, setTextQuestion] = useState<string>(defaultMessage || "");
    const [isRecording, setIsRecording] = useState<boolean>(false);
    const [offset, setOffset] = useState<number>(0);
    const [hasMore, setHasMore] = useState<boolean>(true);
    const [isRecordingMode, setIsRecordingMode] = useState<boolean>(false); // ë…¹ìŒ ëª¨ë“œ ì—¬ë¶€
    const [inputPlaceholder, setInputPlaceholder] = useState<string>("ì—¬í–‰ ì¹œêµ¬ì—ê²Œ ê´€ê´‘ì§€ì— ëŒ€í•´ ì§ˆë¬¸í•˜ì„¸ìš”!"); // ì§ˆë¬¸ì°½ placeholder í…ìŠ¤íŠ¸

    const messageIdRef = useRef<number>(0); // ë©”ì‹œì§€ ê³ ìœ  ID ref
    const chatContainerRef = useRef<HTMLDivElement | null>(null);

    const messagesContainerRef = useRef<HTMLDivElement | null>(null);
    const mediaRecorderRef = useRef<MediaRecorder | null>(null); // MediaRecorder ê°ì²´ë¥¼ ì°¸ì¡°
    const audioChunksRef = useRef<Blob[]>([]); // ë…¹ìŒëœ ë°ì´í„° ì €ì¥ìš© ë°°ì—´
    const audioPlaybackRef = useRef<HTMLAudioElement | null>(null); // ì˜¤ë””ì˜¤ í”Œë ˆì´ë°± ì°¸ì¡°
    const audioBlobRef = useRef<Blob | null>(null); // ë…¹ìŒëœ ì˜¤ë””ì˜¤ Blob ì°¸ì¡°
    const recognitionRef = useRef<any>(null); // SpeechRecognition ì°¸ì¡°

    const navigate = useNavigate();

    const limit = 5;

    useEffect(() => {
        // const jwtToken = localStorage.getItem("jwt");
        // console.log("JWT Token:", jwtToken); // ë””ë²„ê¹…ìš© ë¡œê·¸ ì¶”ê°€
        // if (!jwtToken || jwtToken === "undefined") {
        //     alert("ë¡œê·¸ì¸ í›„ ì‚¬ìš©í•´ì£¼ì„¸ìš”.");
        //     navigate("/auth/login"); // ë¡œê·¸ì¸ í˜ì´ì§€ë¡œ ë¦¬ë‹¤ì´ë ‰íŠ¸
        //     return;
        // }
        loadChatHistory();
        if (defaultMessage.length > 0) {
            setTextQuestion(defaultMessage);
            handleSendQuestion();
        }

    }, []);
    // messages ë³€ê²½ë  ë•Œ ìë™ìœ¼ë¡œ ì‹¤í–‰
    useEffect(() => {
        console.log("ğŸ“© messages ìƒíƒœ ë³€ê²½ë¨! ìƒˆë¡œìš´ ë©”ì‹œì§€ ìˆ˜:", messages.length);
        setTimeout(() => {
            scrollToBottomOfChatContainer();
        }, 100);
    }, [messages]);


    // í…ìŠ¤íŠ¸ì—ì„œ <br>ì„ ë Œë”ë§
    const renderTextWithBrTags = (text: string) => {
        // **ë³¼ë“œì²´** -> <b>ë³¼ë“œì²´</b>ë¡œ ë³€í™˜í•˜ê³ , ì¤„ë°”ê¿ˆì€ <br>ë¡œ ë³€í™˜
        const boldText = text.replace(/\*\*(.*?)\*\*/g, '<b>$1</b>'); // **bold** -> <b>bold</b>
        return { __html: boldText.replace(/\n/g, "<br>") }; // ì¤„ë°”ê¿ˆì„ <br>ë¡œ ë³€í™˜
    };

    const generateMessageId = () => {
        messageIdRef.current += 1;
        return messageIdRef.current;
    };

    const loadChatHistory = async () => {
        try {
            const currentOffset = offset;
            const data = await getChatHistory(currentOffset, limit);

            if (data && data.length > 0) {
                const formattedMessages: Message[] = data
                    .reverse()
                    .map((item: any) => [
                        { id: generateMessageId(), type: "user", text: `${item.conversationQuestion}`, isNew: false },
                        { id: generateMessageId(), type: "bot", text: `${item.conversationAnswer}`, isNew: false },
                    ])
                    .flat();

                setMessages((prev) => [...formattedMessages, ...prev]);
                setOffset(currentOffset + limit);
                setHasMore(data.length >= limit);
            } else {
                setHasMore(false);
            }
        } catch (error) {
            console.error("Failed to load chat history:", error);
        }
    };

    const scrollToBottomOfChatContainer = () => {
        if (chatContainerRef.current && messagesContainerRef.current) {
            console.log("âœ… scrollToBottomOfChatContainer ì‹¤í–‰ë¨!");
            console.log("ğŸ“ í˜„ì¬ chatContainer ìŠ¤í¬ë¡¤ ìœ„ì¹˜:", chatContainerRef.current.scrollTop);
            console.log("ğŸ“ ì „ì²´ chatContainer ë†’ì´:", chatContainerRef.current.scrollHeight);
            console.log("ğŸ“ messagesContainer ë†’ì´:", messagesContainerRef.current.scrollHeight);
    
            requestAnimationFrame(() => {
                chatContainerRef.current!.scrollTop = messagesContainerRef.current!.scrollHeight;
                console.log("ğŸ“Œ ìŠ¤í¬ë¡¤ ì´ë™ ì™„ë£Œ! ìƒˆë¡œìš´ ìœ„ì¹˜:", chatContainerRef.current!.scrollTop);
            });
        } else {
            console.log("âš  chatContainerRef ë˜ëŠ” messagesContainerRefê°€ nullì…ë‹ˆë‹¤!");
        }
    };
    
    const handleSendQuestion = async () => {
        if (!textQuestion.trim()) {
            alert("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”.");
            return;
        }

        const userMessage: Message = { id: generateMessageId(), type: "user", text: textQuestion };
        const loadingMessage: Message = { id: generateMessageId(), type: "bot", text: "loading", isNew: true };

        console.log("Sending question:", userMessage);
        console.log("Adding loading message:", loadingMessage);

        setMessages((prev) => [...prev, userMessage, loadingMessage]);
        setTextQuestion(""); // ì§ˆë¬¸ ì…ë ¥ì°½ ì´ˆê¸°í™”
        scrollToBottomOfChatContainer();

        try {
            const data = await sendTextQuestion(userMessage.text);

            console.log("Received response:", data);

            // ì‹¤ì œ ì‘ë‹µ ë©”ì‹œì§€ë¡œ êµì²´ (isNew ìœ ì§€)
            setMessages((prev) =>
                prev.map((msg) =>
                    msg.id === loadingMessage.id
                        ? {
                            ...msg,
                            text: data.conversation_history.history && data.conversation_history.history.length > 0
                                ? `${data.conversation_history.history[0].assistant_response || "No answer provided."}`
                                : "ì„œë²„ ì—°ê²°ì´ ì‹¤íŒ¨í•˜ì˜€ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.",
                            isNew: true
                        }
                        : msg
                )
            );

            if (data.file_url) {
                playAudioFromUrl(data.file_url);
            }

            scrollToBottomOfChatContainer();

        } catch (error) {
            console.error("Failed to send question:", error);
            // ì—ëŸ¬ ë°œìƒ ì‹œ ë¡œë”© ë©”ì‹œì§€ ì œê±° ë° ì—ëŸ¬ ë©”ì‹œì§€ ì¶”ê°€
            setMessages((prev) =>
                prev.filter((msg) => msg.id !== loadingMessage.id).concat({
                    id: generateMessageId(),
                    type: "bot",
                    text: "ë‹µë³€ì„ ê°€ì ¸ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.",
                    isNew: true
                })
            );
        }
    };

    // ìŒì„± ë…¹ìŒ ì‹œì‘
    const handleStartRecording = async () => {
        console.log("handleStartRecording í˜¸ì¶œë¨");

        // ê¸°ì¡´ ë…¹ìŒ ë°ì´í„°ì™€ ì˜¤ë””ì˜¤ Blob ì´ˆê¸°í™”
        audioChunksRef.current = [];
        audioBlobRef.current = null;

        // ë…¹ìŒ ì¤‘ì´ë¼ë©´, ê¸°ì¡´ì˜ ë…¹ìŒì„ ì¤‘ì§€í•˜ê³  ì´ˆê¸°í™”
        if (isRecording) {
            handleStopRecording();
        }

        const audioPlayback = audioPlaybackRef.current;
        if (audioPlayback) {
            // ì´ì „ ì˜¤ë””ì˜¤ ì¬ìƒ ì¤‘ì§€ ë° ë¦¬ì…‹
            audioPlayback.pause();
            audioPlayback.currentTime = 0;
        }

        console.log("ë…¹ìŒ ì‹œì‘");
        setIsRecording(true); // ë…¹ìŒ ìƒíƒœë¡œ ì„¤ì •
        setIsRecordingMode(true); // ë…¹ìŒ ëª¨ë“œ í™œì„±í™”
        setInputPlaceholder("ìŒì„± ì¸ì‹ ì¤‘..."); // ì§ˆë¬¸ì°½ í…ìŠ¤íŠ¸ ë³€ê²½

        try {
            // ì‚¬ìš©ì ë¯¸ë””ì–´(ë§ˆì´í¬) ì ‘ê·¼
            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
            console.log("ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¼ íšë“:", stream);

            // MediaRecorder ìƒì„± ì‹œ MIME íƒ€ì… ëª…ì‹œì ìœ¼ë¡œ ì„¤ì •
            const options = { mimeType: 'audio/webm; codecs=opus' };
            let mediaRecorder: MediaRecorder;

            if (MediaRecorder.isTypeSupported(options.mimeType)) {
                mediaRecorder = new MediaRecorder(stream, options);
            } else {
                // ì§€ì›ë˜ì§€ ì•ŠëŠ” ê²½ìš° ê¸°ë³¸ MIME íƒ€ì… ì‚¬ìš©
                mediaRecorder = new MediaRecorder(stream);
                console.warn("ì§€ì •í•œ MIME íƒ€ì…ì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ê¸°ë³¸ MIME íƒ€ì…ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.");
            }

            mediaRecorderRef.current = mediaRecorder; // mediaRecorder ì°¸ì¡°

            // MediaRecorder MIME íƒ€ì… í™•ì¸
            console.log("MediaRecorder MIME type:", mediaRecorder.mimeType);

            // ìŒì„± ì¸ì‹ ê°ì²´ ì„¤ì •
            const SpeechRecognition = (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition;
            if (!SpeechRecognition) {
                alert("Speech Recognition APIë¥¼ ì§€ì›í•˜ì§€ ì•ŠëŠ” ë¸Œë¼ìš°ì €ì…ë‹ˆë‹¤.");
                setIsRecording(false);
                setIsRecordingMode(false);
                setInputPlaceholder("ì—¬í–‰ ì¹œêµ¬ì—ê²Œ ê´€ê´‘ì§€ì— ëŒ€í•´ ì§ˆë¬¸í•˜ì„¸ìš”!");
                return;
            }

            const recognition = new SpeechRecognition();
            recognition.lang = "ko-KR";
            recognition.interimResults = true;
            recognition.continuous = true;

            recognition.onresult = (event: any) => {
                // ì‹¤ì‹œê°„ìœ¼ë¡œ ìŒì„± í…ìŠ¤íŠ¸ ë³€í™˜
                const transcript = Array.from(event.results)
                    .map((result: any) => result[0].transcript)
                    .join("");
                setTextQuestion(transcript); // í…ìŠ¤íŠ¸ ì…ë ¥ì°½ì— ì‹¤ì‹œê°„ ë°˜ì˜
            };

            recognition.onerror = (error: any) => {
                console.error("Speech recognition error:", error);
            };

            recognitionRef.current = recognition; // recognition ê°ì²´ ì°¸ì¡°
            recognition.start(); // ìŒì„± ì¸ì‹ ì‹œì‘

            mediaRecorder.ondataavailable = (event) => {
                console.log("ë°ì´í„° ìˆ˜ì§‘ë¨:", event.data);
                audioChunksRef.current.push(event.data); // ìŒì„± ë°ì´í„°ë¥¼ ë°°ì—´ì— ì¶”ê°€
            };

            mediaRecorder.onstop = () => {
                console.log("mediaRecorder onstop í˜¸ì¶œë¨");
                // ë…¹ìŒ ì¢…ë£Œ í›„ ì˜¤ë””ì˜¤ Blob ìƒì„± (MIME íƒ€ì… ì¼ì¹˜)
                const audio = new Blob(audioChunksRef.current, { type: 'audio/webm;codecs=opus' });
                audioBlobRef.current = audio; // ë…¹ìŒëœ ì˜¤ë””ì˜¤ Blob ì°¸ì¡°
                console.log("ë…¹ìŒ ì¢…ë£Œ, Blob í¬ê¸°:", audio.size);
            };

            mediaRecorder.onerror = (error) => {
                console.error("mediaRecorder ì—ëŸ¬:", error);
            };

            mediaRecorder.start(); // ë…¹ìŒ ì‹œì‘
            console.log("MediaRecorder ì‹œì‘ë¨");
        } catch (error) {
            console.error("Failed to start recording:", error);
            setIsRecording(false);
            setIsRecordingMode(false);
            setInputPlaceholder("ì—¬í–‰ ì¹œêµ¬ì—ê²Œ ê´€ê´‘ì§€ì— ëŒ€í•´ ì§ˆë¬¸í•˜ì„¸ìš”!");
        }
    };

    // ìŒì„± ë…¹ìŒ ì¤‘ì§€
    const handleStopRecording = () => {
        console.log("handleStopRecording í˜¸ì¶œë¨");
        setIsRecording(false); // ë…¹ìŒ ì¤‘ì§€ ìƒíƒœ
        setIsRecordingMode(false); // ë…¹ìŒ ëª¨ë“œ ë¹„í™œì„±í™”
        setInputPlaceholder("ì—¬í–‰ ì¹œêµ¬ì—ê²Œ ê´€ê´‘ì§€ì— ëŒ€í•´ ì§ˆë¬¸í•˜ì„¸ìš”!"); // í…ìŠ¤íŠ¸ë¡œ ë³µê·€

        if (mediaRecorderRef.current && mediaRecorderRef.current.state !== "inactive") {
            mediaRecorderRef.current.stop(); // MediaRecorder ì¤‘ì§€
            console.log("MediaRecorder ì¤‘ì§€ ìš”ì²­ë¨");
        }

        if (recognitionRef.current) {
            recognitionRef.current.stop(); // SpeechRecognition ì¤‘ì§€
        }
    };

    const handleSendAudio = async () => {
        console.log("handleSendAudio í˜¸ì¶œë¨");
        handleStopRecording(); // ë…¹ìŒ ì¤‘ì§€

        // ë…¹ìŒì´ ì™„ë£Œë˜ê³  audioBlobRef.currentì´ ì„¤ì •ë  ë•Œê¹Œì§€ ëŒ€ê¸°
        setTimeout(async () => {
            if (!audioBlobRef.current || audioBlobRef.current.size === 0) {
                alert("ë…¹ìŒëœ ì˜¤ë””ì˜¤ê°€ ì—†ìŠµë‹ˆë‹¤.");
                console.log("audioBlobì´ nullì´ê±°ë‚˜ í¬ê¸°ê°€ 0ì…ë‹ˆë‹¤.");
                return;
            }

            const audioBlob = audioBlobRef.current;

            // ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
            const userMessage: Message = { id: generateMessageId(), type: "user", text: textQuestion };
            const loadingMessage: Message = { id: generateMessageId(), type: "bot", text: "loading", isNew: true };

            console.log("Sending audio question:", userMessage);
            console.log("Adding loading message:", loadingMessage);

            setMessages((prev) => [...prev, userMessage, loadingMessage]);
            setTextQuestion(""); // í…ìŠ¤íŠ¸ ì…ë ¥ì°½ ì´ˆê¸°í™”

            try {
                const response = await sendAudio(audioBlob); // ì˜¤ë””ì˜¤ ì „ì†¡

                console.log("Received audio response:", response);

                // ì‹¤ì œ ì‘ë‹µ ë©”ì‹œì§€ë¡œ êµì²´ (isNew ìœ ì§€)
                setMessages((prev) =>
                    prev.map((msg) =>
                        msg.id === loadingMessage.id
                            ? {
                                ...msg,
                                text: response.conversation_history.history && response.conversation_history.history.length > 0
                                    ? `${response.conversation_history.history[0]?.assistant_response || "No answer provided."}`
                                    : "ì„œë²„ ì—°ê²°ì´ ì‹¤íŒ¨í•˜ì˜€ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.",
                                isNew: true
                            }
                            : msg
                    )
                );

                if (response.file_url) {
                    playAudioFromUrl(response.file_url);
                }

                scrollToBottomOfChatContainer();
            } catch (error) {
                console.error("Failed to upload audio:", error);
                // ì—ëŸ¬ ë°œìƒ ì‹œ ë¡œë”© ë©”ì‹œì§€ ì œê±° ë° ì—ëŸ¬ ë©”ì‹œì§€ ì¶”ê°€
                setMessages((prev) =>
                    prev.filter((msg) => msg.id !== loadingMessage.id).concat({
                        id: generateMessageId(),
                        type: "bot",
                        text: "ë‹µë³€ì„ ê°€ì ¸ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. \n ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.",
                        isNew: true
                    })
                );
            }
        }, 500); // 500ms ì§€ì—°
    };

    const playAudioFromUrl = (url: string) => {
        const audioPlayback = audioPlaybackRef.current;
        if (audioPlayback) {
            // ì´ì „ ì˜¤ë””ì˜¤ ì¬ìƒ ì¤‘ì§€ ë° ë¦¬ì…‹
            audioPlayback.pause();
            audioPlayback.currentTime = 0;

            // ìºì‹± ë°©ì§€ë¥¼ ìœ„í•´ ê³ ìœ í•œ ì¿¼ë¦¬ íŒŒë¼ë¯¸í„° ì¶”ê°€
            const uniqueUrl = `${url}?t=${new Date().getTime()}`;
            audioPlayback.src = uniqueUrl;

            // ì˜¤ë””ì˜¤ ìš”ì†Œë¥¼ ë‹¤ì‹œ ë¡œë“œ
            audioPlayback.load();

            // ì˜¤ë””ì˜¤ ìš”ì†Œ ë³´ì´ê¸°
            audioPlayback.style.display = "block";

            // ì˜¤ë””ì˜¤ ì¬ìƒ
            audioPlayback.play().catch((err) => console.error("ì˜¤ë””ì˜¤ ì¬ìƒ ì‹¤íŒ¨:", err));
        }
    };

    // const displayMessage = (message: { type: "user" | "bot"; text: string }) => {
    //     const newMessage: Message = { id: generateMessageId(), ...message };
    //     setMessages((prevMessages) => [...prevMessages, newMessage]);
    //     scrollToBottomOfContainer(); // ë©”ì‹œì§€ ì¶”ê°€ í›„ ìŠ¤í¬ë¡¤ ì´ë™
    // };

    const handleKeyDown = (e: React.KeyboardEvent<HTMLInputElement>) => {
        if (e.key === "Enter") {
            e.preventDefault();  // ê¸°ë³¸ Enter ë™ì‘ ë°©ì§€
            handleSendQuestion();  // ë©”ì‹œì§€ ì „ì†¡ í•¨ìˆ˜ í˜¸ì¶œ
        }
    };

    return (
        <div id="chatContainer" ref={chatContainerRef}>
            {/*<Header />*/}
            <div id="messagesContainer" ref={messagesContainerRef}>
                <AiGuideChat messages={messages} hasMore={hasMore} loadMore={loadChatHistory} />
            </div>
            <div id="inputWrapper">
                <div id="userInputContainer">
                    <input
                        type="text"
                        id="textQuestion"
                        value={textQuestion}
                        onChange={(e) => setTextQuestion(e.target.value)}
                        onKeyDown={handleKeyDown} // ì—”í„°í‚¤ ê°€ëŠ¥í•˜ê²Œ
                        placeholder={inputPlaceholder}
                        disabled={isRecordingMode}
                        required
                    />

                    {/* í…ìŠ¤íŠ¸ ì§ˆë¬¸ ì „ì†¡ ë²„íŠ¼ */}
                    {!isRecording && (
                        <button id="sendButton" onClick={handleSendQuestion}>
                            <img src={arrowUp} alt="Arrow Icon" width="24" height="24" />
                        </button>
                    )}

                    {/* í…ìŠ¤íŠ¸ ì „ì†¡ ëª¨ë“œë¡œ ë³€ê²½ ë²„íŠ¼ */}
                    {isRecordingMode && isRecording && (
                        <button id="stopButton" onClick={handleStopRecording}>
                            <img src={keyboard} alt="Keyboard Icon" width="24" height="24" />
                        </button>
                    )}

                    {/* ë…¹ìŒ ì‹œì‘ ë²„íŠ¼ */}
                    {!isRecording && (
                        <button id="startRecordingButton" onClick={handleStartRecording}>
                            <img src={microphone} alt="Microphone Icon" width="24" height="24" />
                        </button>
                    )}

                    {/* ë…¹ìŒ ì¢…ë£Œ ë° ì „ì†¡ ë²„íŠ¼ */}
                    {isRecording && isRecordingMode && (
                        <button id="stopRecordingButton" onClick={handleSendAudio}>
                            <img src={arrowUp} alt="Arrow Icon" width="24" height="24" />
                        </button>
                    )}
                </div>
            </div>
            <div id="audioContainer">
                <audio id="audioPlayback" ref={audioPlaybackRef} controls style={{ display: "none" }} />
            </div>
        </div>
    );
};

export default AiGuide;
